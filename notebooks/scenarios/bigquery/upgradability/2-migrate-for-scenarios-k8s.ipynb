{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import os\n",
    "from os import environ as env\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy\n",
    "from syft.service.action.action_object import AnyActionObject\n",
    "from syft.service.user.user_roles import ServiceRole\n",
    "from syft.util.test_helpers.email_helpers import load_users\n",
    "from syft.util.test_helpers.job_helpers import create_simple_query_job\n",
    "from syft.util.test_helpers.job_helpers import create_wrong_syntax_query\n",
    "from syft.util.test_helpers.job_helpers import load_jobs\n",
    "from syft.util.util import find_base_dir_with_tox_ini\n",
    "from syft.util.util import get_caller_file_path\n",
    "from syft.util.util import is_interpreter_jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start the cluster\n",
    "- switch to pysyftclone, and go to 0.9.1 and \n",
    "    - export DEVSPACE_PROFILE=bigquery-scenario-tests\n",
    "    - tox -e dev.k8s.destroy\n",
    "    - tox -e dev.k8s.start\n",
    "    - tox -e dev.k8s.deploy\n",
    "2. Prepare the file\n",
    "- go to normal pysyft dev (tox will create the right environment with 0.9.1 for you), edit some files\n",
    "\n",
    "`tox -e migration.scenarios.k8s.prepare`\n",
    "\n",
    "this will create migration.yaml\n",
    "\n",
    "3. Start new cluster\n",
    "- copy migration_k8s.yaml (in scenario notebooks), to grid/helm/examples/dev as migration.yaml\n",
    "- export DEVSPACE_PROFILE=migrated-datasite\n",
    "- tox -e dev.k8s.start\n",
    "- tox -e dev.k8s.deploy\n",
    "\n",
    "4. Run this File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp ./migration_k8s.yaml /Users/koen/workspace/PySyft/packages/grid/helm/examples/dev/migration.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare, run with the right profile\n",
    "\n",
    "```\n",
    "export DEVSPACE_PROFILE=bigquery-scenario-tests\n",
    "tox -e dev.k8s.start\n",
    "tox -e dev.k8s.deploy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_helper_path_to_python_path() -> None:\n",
    "    current_path = \".\"\n",
    "\n",
    "    # jupyter uses \".\" which resolves to the notebook\n",
    "    if not is_interpreter_jupyter():\n",
    "        # python uses the file which has from syft import test_settings in it\n",
    "        import_path = get_caller_file_path()\n",
    "        if import_path:\n",
    "            current_path = import_path\n",
    "\n",
    "    base_dir = find_base_dir_with_tox_ini(current_path)\n",
    "    notebook_helper_path = os.path.join(base_dir, \"test_helpers\")\n",
    "    sys.path.append(notebook_helper_path)\n",
    "\n",
    "    notebook_helper_path = os.path.join(\n",
    "        base_dir, \"notebooks/scenarios/bigquery/upgradability/0.9.1_helpers\"\n",
    "    )\n",
    "    sys.path.append(notebook_helper_path)\n",
    "\n",
    "\n",
    "add_helper_path_to_python_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_EMAIL = \"info@openmined.org\"\n",
    "ROOT_PASSWORD = \"changethis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when in k8s these are the default values\n",
    "ROOT_EMAIL = \"admin@bigquery.org\"\n",
    "ROOT_PASSWORD = \"bqpw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we are not in k8s we set them here for orchestra to use\n",
    "env[\"DEFAULT_ROOT_EMAIL\"] = ROOT_EMAIL\n",
    "env[\"DEFAULT_ROOT_PASSWORD\"] = ROOT_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env[\"ORCHESTRA_DEPLOYMENT_TYPE\"] = \"remote\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from email_helpers import get_email_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_server, smtp_server = get_email_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = sy.orchestra.launch(\n",
    "    name=\"bigquery-high-migrations\",\n",
    "    dev_mode=True,\n",
    "    server_side_type=\"high\",\n",
    "    reset=True,\n",
    "    port=\"8080\",\n",
    "    n_consumers=1,  # How many workers to be spawned\n",
    "    create_producer=True,  # Can produce more workers\n",
    ")\n",
    "\n",
    "client = sy.login(url=\"http://localhost:8080\", email=ROOT_EMAIL, password=ROOT_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this is a new server\n",
    "migration_data = client.get_migration_data()\n",
    "\n",
    "# assert len(migration_data.store_objects[User]) == 1\n",
    "# assert UserCode not in migration_data.store_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load migration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_data_dir = Path(os.getenv(\"MIGRATION_DATA_DIR\", \".\"))\n",
    "blob_path = migration_data_dir / \"migration_k8s.blob\"\n",
    "yaml_path = migration_data_dir / \"migration_k8s.yaml\"\n",
    "\n",
    "print(f\"Loading migration data from {str(blob_path.resolve())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.load_migration_data(blob_path)\n",
    "assert isinstance(res, sy.SyftSuccess), res.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from syft.service.migration.object_migration_state import MigrationData\n",
    "\n",
    "# migration_data = MigrationData.from_file(blob_path)\n",
    "\n",
    "# worker_pools = migration_data.get_items_by_canonical_name(\"WorkerPool\")\n",
    "\n",
    "# pool = worker_pools[0]\n",
    "\n",
    "# images = migration_data.get_items_by_canonical_name(\"SyftWorkerImage\")\n",
    "# image_id = pool.image_id\n",
    "# old_image = [img for img in images if img.id == image_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_image.is_prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker_pools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -f bigquery.dockerfile -t test ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker image tag test k3d-registry.localhost:5800/openmined/test:dev-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push k3d-registry.localhost:5800/openmined/test:dev-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = sy.PrebuiltWorkerConfig(\n",
    "    tag=\"k3d-registry.localhost:5800/openmined/test:dev-latest\", description=\"\"\n",
    ")\n",
    "\n",
    "print(\"submitting new prebuilt image...\")\n",
    "result = client.api.services.worker_image.submit(worker_config=new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uid = result.value.id  # or client.images[i].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.api.services.worker_pool.launch(\n",
    "    pool_name=\"bigquery-pool\",\n",
    "    image_uid=image_uid,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sy.upgrade_custom_workerpools(client, blob_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.register(\n",
    "    name=\"abcdef\",\n",
    "    email=\"ab@de.org\",\n",
    "    password=\"abc\",\n",
    "    password_verify=\"abc\",\n",
    "    institution=\"comp\",\n",
    "    website=\"www.a.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(email_server.load_emails()[\"ab@de.org\"]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post migration tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = load_users(client, path=\"0.9.1_notebooks/users_k8s.json\")\n",
    "jobs = load_jobs(users, client, filepath=\"0.9.1_notebooks/jobs_k8s.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_users = client.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_users[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_user_names = [\n",
    "    user.name for user in server_users if user.role == ServiceRole.DATA_SCIENTIST\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names = [user.name for user in users] + [\"abcdef\"]  # new registered user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(server_user_names) == set(user_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitted_jobs = [job for job in jobs if job.is_submitted]\n",
    "reviewed_jobs = [job for job in jobs if job.admin_reviewed]\n",
    "reviewed_jobs_should_succeed = [j for j in reviewed_jobs if j.should_succeed]\n",
    "reviewed_jobs_should_fail = [j for j in reviewed_jobs if not j.should_succeed]\n",
    "\n",
    "print(\n",
    "    f\"{len(reviewed_jobs)=}, {len(reviewed_jobs_should_succeed)=}, {len(reviewed_jobs_should_fail)=}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in reviewed_jobs_should_succeed:\n",
    "    print(f\"> Checking job: {job.job_type} {job.func_name} for user {job.user_email}\")\n",
    "    api_method = job.code_method\n",
    "    j = api_method(blocking=False)\n",
    "    res = j.wait()\n",
    "\n",
    "    if isinstance(res, sy.SyftError):\n",
    "        raise sy.SyftException(public_message=res.message)\n",
    "\n",
    "    result = res.get()\n",
    "    job.result_as_expected = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in reviewed_jobs_should_fail:\n",
    "    print(f\"> Checking job: {job.job_type} {job.func_name} for user {job.user_email}\")\n",
    "    api_method = job.code_method\n",
    "\n",
    "    j = api_method(blocking=False)\n",
    "    res = j.wait()\n",
    "    if isinstance(res, sy.SyftError):\n",
    "        job.result_as_expected = True\n",
    "    else:\n",
    "        raise sy.SyftException(public_message=f\"failed, job didnt raise {type(j)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_jobs = [job for job in jobs if job.result_as_expected]\n",
    "print(f\"got expected_jobs: {len(expected_jobs)} == reviewed_jobs: {len(reviewed_jobs)}\")\n",
    "assert len(reviewed_jobs) == len(expected_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use old DS to go through the flow again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_client = users[0].client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ds_client.api.services.api.api_endpoints()) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = create_simple_query_job(users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ds_client.api.services.bigquery.submit_query(\n",
    "    func_name=job.func_name, query=job.query\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(response, AnyActionObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in client.requests:\n",
    "    if request.code.service_func_name == job.func_name:\n",
    "        request.approve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_res = getattr(ds_client.code, job.func_name)(blocking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_res.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from pandas import DataFrame\n",
    "\n",
    "assert isinstance(job_res.result.get(), DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_syntax_job = create_wrong_syntax_query(users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ds_client.api.services.bigquery.submit_query(\n",
    "    func_name=wrong_syntax_job.func_name, query=wrong_syntax_job.query\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(response, AnyActionObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in client.requests:\n",
    "    if request.code.service_func_name == wrong_syntax_job.func_name:\n",
    "        request.approve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_res = getattr(ds_client.code, wrong_syntax_job.func_name)(blocking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(job_res.wait(), sy.SyftError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if server.server_type.value == \"python\":\n",
    "    server.land()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
